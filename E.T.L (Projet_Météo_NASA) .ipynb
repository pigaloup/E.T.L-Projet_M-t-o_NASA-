{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c48d5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import concurrent.futures\n",
    "import mysql.connector\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, substring, to_date, concat_ws, lit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c7ed73",
   "metadata": {},
   "source": [
    "# CONFIGURATION DU LOGGING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c500c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='etl_execution.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae948016",
   "metadata": {},
   "source": [
    "#  ÉTAPE 1 : EXTRACTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db15eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les dates AVANT toute utilisation\n",
    "date_actuelle = datetime.today()\n",
    "date_delay = date_actuelle - timedelta(days=8)\n",
    "end_date = date_delay.strftime(\"%Y%m%d\")\n",
    "\n",
    "start_date_delay = date_delay - timedelta(days=75)\n",
    "start_date = start_date_delay.strftime(\"%Y%m%d\")\n",
    "\n",
    "# Dictionnaire des coordonnées\n",
    "pays_coordinee = {\n",
    "    \"senegal\": {\n",
    "        \"dakar\": (14.6928, -17.4467),\n",
    "        \"thies\": (14.7894, -16.926),\n",
    "        \"saint-louis\": (16.0333, -16.5),\n",
    "        \"kaolack\": (14.151, -16.0726),\n",
    "        \"ziguinchor\": (12.5833, -16.2667),\n",
    "        \"tambacounda\": (13.77, -13.6672),\n",
    "        \"kedougou\": (12.5535, -12.1743),\n",
    "    },\n",
    "    \"mali\": {\n",
    "        \"bamako\": (12.6392, -8.0029),\n",
    "        \"segou\": (13.4317, -6.2157),\n",
    "        \"timbuktu\": (16.7666, -3.0026),\n",
    "        \"mopti\": (14.4843, -4.1827),\n",
    "    },\n",
    "    \"cote_d_ivoire\": {\n",
    "        \"abidjan\": (5.3364, -4.0261),\n",
    "        \"bouake\": (7.6833, -5.0333),\n",
    "        \"yamoussoukro\": (6.8161, -5.2742),\n",
    "        \"san_pedro\": (4.7485, -6.6363),\n",
    "    },\n",
    "    \"guinee\": {\n",
    "        \"conakry\": (9.6412, -13.5784),\n",
    "        \"kankan\": (10.3842, -9.3057),\n",
    "        \"n_zerekore\": (7.7594, -8.8174),\n",
    "        \"labé\": (11.3167, -12.2833),\n",
    "    },\n",
    "    \"nigeria\": {\n",
    "        \"lagos\": (6.5244, 3.3792),\n",
    "        \"abuja\": (9.0579, 7.4951),\n",
    "        \"kano\": (12.0022, 8.5919),\n",
    "    },\n",
    "    \"ghana\": {\n",
    "        \"accra\": (5.6037, -0.187),\n",
    "        \"kumasi\": (6.6666, -1.6163),\n",
    "        \"tamale\": (9.4075, -0.8531),\n",
    "        \"takoradi\": (4.8975, -1.7603),\n",
    "    },\n",
    "    \"burkina faso\": {\n",
    "        \"ouagadougou\": (12.3714, -1.5197),\n",
    "        \"bobo dioulasso\": (11.1786, -4.2979),\n",
    "        \"koudougou\": (12.2542, -2.3625),\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# Fonction principale\n",
    "def get_data(pays_list, start_date, end_date):\n",
    "    dfs = []\n",
    "    # Générer l’URL NASA\n",
    "    def __get_url__(lat:str, long:str, start_date:str, end_date:str)->str:\n",
    "        return f\"https://power.larc.nasa.gov/api/temporal/hourly/point?parameters=T2M,RH2M,T2MWET,PRECTOTCORR,WS10M,WD10M,T2MDEW,V10M,PS,QV2M,U10M&community=AG&longitude={long}&latitude={lat}&start={start_date}&end={end_date}&format=json\"\n",
    "\n",
    "    # Convertir les données JSON en DataFrame\n",
    "    def __convert_to_df_optimized__(parameters, city, county):\n",
    "        dates = list(parameters['T2M'].keys())\n",
    "        n_dates = len(dates)\n",
    "        data = {\n",
    "            'date': dates,\n",
    "            'ville': [city] * n_dates,\n",
    "            'pays': [county] * n_dates\n",
    "        }\n",
    "        for param in parameters:\n",
    "            data[param] = [parameters[param].get(date, None) for date in dates]\n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def fetch_city_data(pays, ville, coordonate):\n",
    "        lat, long = coordonate\n",
    "        url = __get_url__(lat=lat, long=long, start_date=start_date, end_date=end_date)\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            data = response.json()[\"properties\"][\"parameter\"]\n",
    "            return __convert_to_df_optimized__(parameters=data, city=ville, county=pays)\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur pour {ville}, {pays}: {e}\")\n",
    "            return None\n",
    "\n",
    "    tasks = []\n",
    "    for pays_loop in pays_list:\n",
    "        if pays_loop.lower() not in [p.lower() for p in pays_coordinee.keys()]:\n",
    "            print(f\"Ce pays n'est pas pris en compte: {pays_loop}\")\n",
    "            continue\n",
    "        villes = pays_coordinee[pays_loop.lower()]\n",
    "        for ville, coordonate in villes.items():\n",
    "            tasks.append((pays_loop, ville, coordonate))\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(fetch_city_data, pays, ville, coord) for pays, ville, coord in tasks]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                dfs.append(result)\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "# Exécution\n",
    "df = get_data([\"Senegal\",\"mali\",\"cote_d_ivoire\",\"guinee\",\"nigeria\",\"ghana\",\"burkina faso\"], start_date, end_date)\n",
    "df.to_csv(\"Nasa_Power_data_PAYS.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06864eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ville</th>\n",
       "      <th>pays</th>\n",
       "      <th>T2M</th>\n",
       "      <th>RH2M</th>\n",
       "      <th>T2MWET</th>\n",
       "      <th>PRECTOTCORR</th>\n",
       "      <th>WS10M</th>\n",
       "      <th>WD10M</th>\n",
       "      <th>T2MDEW</th>\n",
       "      <th>V10M</th>\n",
       "      <th>PS</th>\n",
       "      <th>QV2M</th>\n",
       "      <th>U10M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025072600</td>\n",
       "      <td>bamako</td>\n",
       "      <td>mali</td>\n",
       "      <td>24.21</td>\n",
       "      <td>85.41</td>\n",
       "      <td>22.92</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.39</td>\n",
       "      <td>200.9</td>\n",
       "      <td>21.62</td>\n",
       "      <td>2.23</td>\n",
       "      <td>96.76</td>\n",
       "      <td>16.77</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025072601</td>\n",
       "      <td>bamako</td>\n",
       "      <td>mali</td>\n",
       "      <td>23.76</td>\n",
       "      <td>87.03</td>\n",
       "      <td>22.62</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.23</td>\n",
       "      <td>201.8</td>\n",
       "      <td>21.49</td>\n",
       "      <td>2.07</td>\n",
       "      <td>96.71</td>\n",
       "      <td>16.64</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025072602</td>\n",
       "      <td>bamako</td>\n",
       "      <td>mali</td>\n",
       "      <td>23.47</td>\n",
       "      <td>88.29</td>\n",
       "      <td>22.46</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.23</td>\n",
       "      <td>202.4</td>\n",
       "      <td>21.45</td>\n",
       "      <td>2.06</td>\n",
       "      <td>96.69</td>\n",
       "      <td>16.59</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025072603</td>\n",
       "      <td>bamako</td>\n",
       "      <td>mali</td>\n",
       "      <td>23.24</td>\n",
       "      <td>89.63</td>\n",
       "      <td>22.35</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.29</td>\n",
       "      <td>205.6</td>\n",
       "      <td>21.46</td>\n",
       "      <td>2.07</td>\n",
       "      <td>96.70</td>\n",
       "      <td>16.61</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025072604</td>\n",
       "      <td>bamako</td>\n",
       "      <td>mali</td>\n",
       "      <td>23.08</td>\n",
       "      <td>90.60</td>\n",
       "      <td>22.29</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.50</td>\n",
       "      <td>212.4</td>\n",
       "      <td>21.49</td>\n",
       "      <td>2.11</td>\n",
       "      <td>96.74</td>\n",
       "      <td>16.62</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   ville  pays    T2M   RH2M  T2MWET  PRECTOTCORR  WS10M  WD10M  \\\n",
       "0  2025072600  bamako  mali  24.21  85.41   22.92         0.14   2.39  200.9   \n",
       "1  2025072601  bamako  mali  23.76  87.03   22.62         0.15   2.23  201.8   \n",
       "2  2025072602  bamako  mali  23.47  88.29   22.46         0.19   2.23  202.4   \n",
       "3  2025072603  bamako  mali  23.24  89.63   22.35         0.24   2.29  205.6   \n",
       "4  2025072604  bamako  mali  23.08  90.60   22.29         0.22   2.50  212.4   \n",
       "\n",
       "   T2MDEW  V10M     PS   QV2M  U10M  \n",
       "0   21.62  2.23  96.76  16.77  0.85  \n",
       "1   21.49  2.07  96.71  16.64  0.83  \n",
       "2   21.45  2.06  96.69  16.59  0.85  \n",
       "3   21.46  2.07  96.70  16.61  0.99  \n",
       "4   21.49  2.11  96.74  16.62  1.34  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Nasa_Power_data_PAYS.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed058958",
   "metadata": {},
   "source": [
    "#  ÉTAPE 2 : TRANSFORMATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7eb17d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, substring, concat_ws, lit\n",
    "\n",
    "# Initialisation Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Météo\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Lecture du fichier CSV avec pandas\n",
    "df_read = pd.read_csv(\"Nasa_Power_data_PAYS.csv\")\n",
    "\n",
    "# Conversion en DataFrame Spark\n",
    "df = spark.createDataFrame(df_read)\n",
    "\n",
    "def transformer_header(df):\n",
    "    # 1. Extraire la date et l'heure depuis la colonne 'date'\n",
    "    df = df.withColumn(\"date_str\", col(\"date\").cast(\"string\"))\n",
    "    df = df.withColumn(\"date_formatted\", to_date(substring(col(\"date_str\"), 1, 8), \"yyyyMMdd\")) \\\n",
    "           .withColumn(\"heure_formatted\", concat_ws(\":\", substring(col(\"date_str\"), 9, 2), lit(\"00\"), lit(\"00\")))\n",
    "\n",
    "    # 2. Sélectionner les colonnes utiles\n",
    "    colonnes_a_exclure = [\"date_str\", \"heure_str\", \"date\", \"heure\", \"date_formatted\", \"heure_formatted\"]\n",
    "    #all_columns = [c for c in df.columns if c not in colonnes_a_exclure]\n",
    "    all_columns = [c for c in df.columns if c not in colonnes_a_exclure]\n",
    "    df = df.select(*all_columns, col(\"date_formatted\").alias(\"date\"), col(\"heure_formatted\").alias(\"heure\"))\n",
    "\n",
    "    # 3. Nettoyage des données\n",
    "    df = df.dropna()\n",
    "    df = df.dropDuplicates()\n",
    "    df = df.filter((col(\"T2MWET\") >= -30) & (col(\"RH2M\") >= -30))\n",
    "\n",
    "    # 4. Renommer les colonnes\n",
    "    header_map = {\n",
    "        'ville': 'ville',\n",
    "        'pays': 'pays',\n",
    "        'T2M': 'temperature_air',\n",
    "        'PS': 'pression',\n",
    "        'WS10M': 'intensite_vent',\n",
    "        'QV2M': 'humidite_specifique',\n",
    "        'T2MDEW': 'temperature_point_rosee',\n",
    "        'U10M': 'composante_est_ouest_vent',\n",
    "        'V10M': 'vitesse_vent',\n",
    "        'RH2M': 'humidite_relative',\n",
    "        'WD10M': 'direction_vent',\n",
    "        'T2MWET': 'temperature_humide',\n",
    "        'PRECTOTCORR': 'precipitations_corrigees',\n",
    "        'date': 'date',\n",
    "        'heure': 'heure'\n",
    "    }\n",
    "\n",
    "    for old_col, new_col in header_map.items():\n",
    "        df = df.withColumnRenamed(old_col, new_col)\n",
    "\n",
    "    return df\n",
    "\n",
    "#df_cleaned = df.toPandas()\n",
    "# Transformation\n",
    "df_cleaned = transformer_header(df)\n",
    "\n",
    "# Export vers CSV\n",
    "df_cleaned.toPandas().to_csv(\"Nasa_Power_data_cleaned_PAYS.csv\", index=False)\n",
    "\n",
    "# Arrêt de Spark\n",
    "spark.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03871db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ville</th>\n",
       "      <th>pays</th>\n",
       "      <th>temperature_air</th>\n",
       "      <th>humidite_relative</th>\n",
       "      <th>temperature_humide</th>\n",
       "      <th>precipitations_corrigees</th>\n",
       "      <th>intensite_vent</th>\n",
       "      <th>direction_vent</th>\n",
       "      <th>temperature_point_rosee</th>\n",
       "      <th>vitesse_vent</th>\n",
       "      <th>pression</th>\n",
       "      <th>humidite_specifique</th>\n",
       "      <th>composante_est_ouest_vent</th>\n",
       "      <th>date</th>\n",
       "      <th>heure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>26.74</td>\n",
       "      <td>88.80</td>\n",
       "      <td>25.75</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3.15</td>\n",
       "      <td>278.0</td>\n",
       "      <td>24.76</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>101.07</td>\n",
       "      <td>19.43</td>\n",
       "      <td>3.12</td>\n",
       "      <td>2025-08-05</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>29.36</td>\n",
       "      <td>75.95</td>\n",
       "      <td>27.03</td>\n",
       "      <td>5.62</td>\n",
       "      <td>4.24</td>\n",
       "      <td>275.4</td>\n",
       "      <td>24.70</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>101.06</td>\n",
       "      <td>19.36</td>\n",
       "      <td>4.22</td>\n",
       "      <td>2025-08-07</td>\n",
       "      <td>09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>26.79</td>\n",
       "      <td>90.79</td>\n",
       "      <td>25.98</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.48</td>\n",
       "      <td>218.9</td>\n",
       "      <td>25.18</td>\n",
       "      <td>2.71</td>\n",
       "      <td>101.27</td>\n",
       "      <td>19.89</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2025-08-10</td>\n",
       "      <td>23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>25.91</td>\n",
       "      <td>93.62</td>\n",
       "      <td>25.36</td>\n",
       "      <td>2.31</td>\n",
       "      <td>3.98</td>\n",
       "      <td>227.6</td>\n",
       "      <td>24.82</td>\n",
       "      <td>2.68</td>\n",
       "      <td>101.16</td>\n",
       "      <td>19.49</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saint-louis</td>\n",
       "      <td>Senegal</td>\n",
       "      <td>31.55</td>\n",
       "      <td>63.82</td>\n",
       "      <td>27.79</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.02</td>\n",
       "      <td>248.9</td>\n",
       "      <td>24.03</td>\n",
       "      <td>1.45</td>\n",
       "      <td>100.72</td>\n",
       "      <td>18.49</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2025-09-06</td>\n",
       "      <td>12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ville     pays  temperature_air  humidite_relative  \\\n",
       "0  saint-louis  Senegal            26.74              88.80   \n",
       "1  saint-louis  Senegal            29.36              75.95   \n",
       "2  saint-louis  Senegal            26.79              90.79   \n",
       "3  saint-louis  Senegal            25.91              93.62   \n",
       "4  saint-louis  Senegal            31.55              63.82   \n",
       "\n",
       "   temperature_humide  precipitations_corrigees  intensite_vent  \\\n",
       "0               25.75                      0.03            3.15   \n",
       "1               27.03                      5.62            4.24   \n",
       "2               25.98                      3.75            3.48   \n",
       "3               25.36                      2.31            3.98   \n",
       "4               27.79                      1.82            4.02   \n",
       "\n",
       "   direction_vent  temperature_point_rosee  vitesse_vent  pression  \\\n",
       "0           278.0                    24.76         -0.44    101.07   \n",
       "1           275.4                    24.70         -0.40    101.06   \n",
       "2           218.9                    25.18          2.71    101.27   \n",
       "3           227.6                    24.82          2.68    101.16   \n",
       "4           248.9                    24.03          1.45    100.72   \n",
       "\n",
       "   humidite_specifique  composante_est_ouest_vent        date     heure  \n",
       "0                19.43                       3.12  2025-08-05  00:00:00  \n",
       "1                19.36                       4.22  2025-08-07  09:00:00  \n",
       "2                19.89                       2.19  2025-08-10  23:00:00  \n",
       "3                19.49                       2.94  2025-08-11  06:00:00  \n",
       "4                18.49                       3.75  2025-09-06  12:00:00  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"Nasa_Power_data_cleaned_PAYS.csv\"\n",
    "df_cleaned = pd.read_csv(dataset_path)\n",
    "df_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d295117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ville', 'pays', 'temperature_air', 'humidite_relative', 'temperature_humide', 'precipitations_corrigees', 'intensite_vent', 'direction_vent', 'temperature_point_rosee', 'vitesse_vent', 'pression', 'humidite_specifique', 'composante_est_ouest_vent', 'date', 'heure']\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b3f012",
   "metadata": {},
   "source": [
    "# ÉTAPE 3 : CHARGEMENT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "424d1215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has 15 columns\n",
      "DataFrame columns: ['ville', 'pays', 'temperature_air', 'humidite_relative', 'temperature_humide', 'precipitations_corrigees', 'intensite_vent', 'direction_vent', 'temperature_point_rosee', 'vitesse_vent', 'pression', 'humidite_specifique', 'composante_est_ouest_vent', 'date', 'heure']\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted final batch of 96 rows\n",
      "Data insertion completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "# Paramètres de connexion\n",
    "DB_NAME = \"meteo_db_PAYS\"\n",
    "TABLE_NAME = \"meteo_data_PAYS\"\n",
    "MYSQL_USER = \"root\"\n",
    "MYSQL_PASSWORD = \"MYCCA\"\n",
    "MYSQL_HOST = \"localhost\"\n",
    "\n",
    "def insert_connector_data(dataframe, batch_size=200):  \n",
    "    # Vérifier que le DataFrame est bien un Pandas DataFrame\n",
    "    if not isinstance(dataframe, pd.DataFrame):\n",
    "        try:\n",
    "            dataframe = dataframe.toPandas()\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur de conversion en DataFrame Pandas : {e}\")\n",
    "            return\n",
    "\n",
    "    # Étape 1 : Créer la base si elle n'existe pas\n",
    "    conn = mysql.connector.connect(\n",
    "        host=MYSQL_HOST,\n",
    "        user=MYSQL_USER,\n",
    "        password=MYSQL_PASSWORD\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {DB_NAME}\")\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    # Étape 2 : Connexion à la base\n",
    "    conn = mysql.connector.connect(\n",
    "        host=MYSQL_HOST,\n",
    "        user=MYSQL_USER,\n",
    "        password=MYSQL_PASSWORD,\n",
    "        database=DB_NAME\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Créer la table si elle n'existe pas\n",
    "    cursor.execute(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {TABLE_NAME} (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            date DATE,\n",
    "            heure VARCHAR(255),\n",
    "            ville VARCHAR(255),\n",
    "            pays VARCHAR(255),\n",
    "            temperature_air FLOAT,\n",
    "            pression FLOAT,\n",
    "            intensite_vent FLOAT,\n",
    "            humidite_specifique FLOAT,\n",
    "            temperature_point_rosee FLOAT,\n",
    "            composante_est_ouest_vent FLOAT,\n",
    "            vitesse_vent FLOAT,\n",
    "            humidite_relative FLOAT,\n",
    "            direction_vent FLOAT,\n",
    "            temperature_humide FLOAT,\n",
    "            precipitations_corrigees FLOAT\n",
    "        );\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    \n",
    "    # Colonnes attendues\n",
    "    expected_columns = [\n",
    "        'date', 'heure', 'ville', 'pays', 'temperature_air', 'pression', 'intensite_vent',\n",
    "        'humidite_specifique', 'temperature_point_rosee', 'composante_est_ouest_vent',\n",
    "        'vitesse_vent', 'humidite_relative', 'direction_vent',\n",
    "        'temperature_humide', 'precipitations_corrigees'\n",
    "    ]\n",
    "    \n",
    "    # Vérifier que toutes les colonnes sont présentes\n",
    "    missing = [col for col in expected_columns if col not in dataframe.columns]\n",
    "    if missing:\n",
    "        print(\"Colonnes manquantes :\", missing)\n",
    "        return\n",
    "    # Vérifier le nombre de colonnes dans le DataFrame\n",
    "    column_count = len(dataframe.columns)\n",
    "    print(f\"DataFrame has {column_count} columns\")\n",
    "    print(f\"DataFrame columns: {dataframe.columns.tolist()}\")\n",
    "    \n",
    "    # Réordonner les colonnes\n",
    "    dataframe = dataframe[expected_columns]\n",
    "    \n",
    "    # Insertion par batch\n",
    "    batch = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        row_tuple = tuple(row.values)\n",
    "        batch.append(row_tuple)\n",
    "        \n",
    "        if len(batch) >= batch_size:\n",
    "            try:\n",
    "                cursor.executemany(\n",
    "                    f\"\"\"INSERT INTO {TABLE_NAME} ({', '.join(expected_columns)}) \n",
    "                        VALUES ({', '.join(['%s'] * len(expected_columns))})\"\"\",\n",
    "                    batch\n",
    "                )\n",
    "                conn.commit()\n",
    "                print(f\"Inserted batch of {len(batch)} rows\")\n",
    "                batch = []\n",
    "            except Exception as e:\n",
    "                print(f\"Error inserting batch: {e}\")\n",
    "                conn.rollback()\n",
    "\n",
    "    # Dernier batch\n",
    "    if batch:\n",
    "        try:\n",
    "            cursor.executemany(\n",
    "                f\"\"\"INSERT INTO {TABLE_NAME} ({', '.join(expected_columns)}) \n",
    "                    VALUES ({', '.join(['%s'] * len(expected_columns))})\"\"\",\n",
    "                batch\n",
    "            )\n",
    "            conn.commit()\n",
    "            print(f\"Inserted final batch of {len(batch)} rows\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error inserting final batch: {e}\")\n",
    "            conn.rollback()\n",
    "\n",
    "    print(\"Data insertion completed\")\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "# Exemple d'appel à la fonction\n",
    "insert_connector_data(df_cleaned, batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122b53e6",
   "metadata": {},
   "source": [
    "# Ce script Python permet t'exécuter toutes les étapes du pipeline E.T.L (Extraction,Transformation, Chargement) pour des données météorologiques provenant de la NASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a45fb91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has 15 columns\n",
      "DataFrame columns: ['ville', 'pays', 'temperature_air', 'humidite_relative', 'temperature_humide', 'precipitations_corrigees', 'intensite_vent', 'direction_vent', 'temperature_point_rosee', 'vitesse_vent', 'pression', 'humidite_specifique', 'composante_est_ouest_vent', 'date', 'heure']\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted batch of 200 rows\n",
      "Inserted final batch of 96 rows\n",
      "Data insertion completed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, substring, concat_ws, lit\n",
    "\n",
    "# Configuration du logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# === MAIN ===\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Définir les dates\n",
    "        date_actuelle = datetime.today()\n",
    "        date_delay = date_actuelle - timedelta(days=8)\n",
    "        end_date = date_delay.strftime(\"%Y%m%d\")\n",
    "        start_date = (date_delay - timedelta(days=75)).strftime(\"%Y%m%d\")\n",
    "\n",
    "        pays_list = [\"Senegal\", \"mali\", \"cote_d_ivoire\", \"guinee\", \"nigeria\", \"ghana\", \"burkina faso\"]\n",
    "\n",
    "        logging.info(\"Début de l'extraction des données\")\n",
    "        df_extrait = get_data(pays_list, start_date, end_date) \n",
    "        df_extrait.to_csv(\"Nasa_Power_data_PAYS.csv\", index=False)\n",
    "        logging.info(\"Fin de l'extraction des données\")\n",
    "\n",
    "        logging.info(\"Initialisation de Spark\")\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"Météo\") \\\n",
    "            .config(\"spark.executor.memory\", \"4g\") \\\n",
    "            .config(\"spark.driver.memory\", \"4g\") \\\n",
    "            .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "        logging.info(\"Début de la transformation des données\")\n",
    "        df_spark = spark.createDataFrame(df_extrait)\n",
    "        df_cleaned = transformer_header(df_spark)\n",
    "        df_cleaned.toPandas().to_csv(\"Nasa_Power_data_cleaned_PAYS.csv\", index=False)\n",
    "        logging.info(\"Fin de la transformation des données\")\n",
    "\n",
    "        logging.info(\"Début du chargement des données\")\n",
    "        insert_connector_data(df_cleaned, batch_size=200)  # Assurez-vous que cette fonction existe\n",
    "        logging.info(\"Fin du chargement des données\")\n",
    "\n",
    "        logging.info(\"Pipeline ETL terminé avec succès\")\n",
    "        spark.stop()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erreur globale du pipeline ETL : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344aad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
