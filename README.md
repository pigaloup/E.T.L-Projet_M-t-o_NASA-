# ğŸŒ Projet E.T.L MÃ©tÃ©o NASA avec Airflow, Spark, MySQL et Analyse MÃ©tÃ©orologique

## ğŸ“Œ Description : 

Ce projet met en place un **pipeline ETL automatisÃ©** pour collecter, transformer et charger des donnÃ©es mÃ©tÃ©orologiques issues de lâ€™API **NASA POWER**.  
Lâ€™objectif est de construire une base de donnÃ©es exploitable pour lâ€™analyse climatique de plusieurs pays dâ€™Afrique de lâ€™Ouest (SÃ©nÃ©gal, Mali, CÃ´te dâ€™Ivoire, GuinÃ©e, Nigeria, Ghana, Burkina Faso).
Le pipeline est orchestrÃ© avec **Apache Airflow**, utilise **Apache Spark** pour la transformation des donnÃ©es, et stocke les rÃ©sultats dans une base **MySQL**.

Le projet comprend Ã©galement des Ã©tapes d'analyse statistique et de visualisation des donnÃ©es dans **Power BI**.

---

## âš™ï¸ Architecture du projet

### Ã‰tapes ETL
1. **Extraction** :
   - RequÃªte API NASA POWER (paramÃ¨tres mÃ©tÃ©o : tempÃ©rature, humiditÃ©, vent, prÃ©cipitations, etc.).
   - DonnÃ©es collectÃ©es pour plusieurs villes par pays.
   - Utilisation de **multithreading** (`concurrent.futures`) pour accÃ©lÃ©rer les appels API.
   - Sauvegarde initiale en **CSV**.

2. **Transformation et nettoyage des donnÃ©es** :
   - Chargement des donnÃ©es brutes dans **PySpark**.
   - Nettoyage : suppression des doublons, gestion des valeurs manquantes, filtrage des anomalies.
   - Conversion des dates en colonnes distinctes pour la date et l'heure.
   - Renommage des colonnes pour plus de lisibilitÃ© (`temperature_air`, `pression`, `humidite_relative`, etc.).
   - Export des donnÃ©es nettoyÃ©es en **CSV**.

3. **Chargement** :
   - Connexion Ã  une base **MySQL**.
   - CrÃ©ation automatique de la base et de la table si elles nâ€™existent pas.
   - Insertion des donnÃ©es par **batchs** pour optimiser les performances.
   - Gestion des erreurs et rollback en cas dâ€™Ã©chec.

4. [**Visualisation des donnÃ©es**](https://github.com/pigaloup/E.T.L-AIRFLOW_Projet_Meteo_NASA-/blob/main/Readme_POWERBI.md) :
Utilisation de **Power BI** pour crÃ©er des visualisations interactives les donnÃ©es mÃ©tÃ©orologiques, en analysant les variables telles que :

---

## ğŸ“‚ Structure du DAG Airflow :

Le DAG `nasa_etl_pipeline` orchestre les 3 Ã©tapes :

- **Task 1 : `extract_data`** â†’ Appelle la fonction `get_data` et sauvegarde le CSV brut.  
- **Task 2 : `transform_data`** â†’ Nettoie et transforme les donnÃ©es avec Spark.  
- **Task 3 : `load_data`** â†’ Charge les donnÃ©es dans MySQL.


## ğŸ–¼ï¸ SchÃ©ma dâ€™architecture du pipeline ETL:

Voici une reprÃ©sentation visuelle du pipeline ETL orchestrÃ© avec Apache Airflow :

![SchÃ©ma dâ€™architecture du pipeline ETL](ETL+AIRFLOW/ETL_ARCHITECTURE.jpg)

---

## ğŸ“Š RÃ©sultats attendus aprÃ©s Ã©xÃ©cution:

- Base MySQL meteo_db_PAYS_AIRFLOW contenant la table meteo_data_PAYS_AIRFLOW.
- DonnÃ©es mÃ©tÃ©orologiques nettoyÃ©es et prÃªtes pour lâ€™analyse.
- Fichiers CSV intermÃ©diaires pour audit et traÃ§abilitÃ©.
- Logs dÃ©taillÃ©s (etl_execution.log) pour suivre lâ€™exÃ©cution.
  
---

## ğŸ› ï¸ CompÃ©tences acquises:

En rÃ©alisant ce projet, jâ€™ai dÃ©veloppÃ© les compÃ©tences suivantes :

**Python avancÃ©** :connexion avec la base de donnÃ©e Mysql, gestion des exceptions, logging, multithreading.
**API REST** : Pour la collecte des donnÃ©es mÃ©tÃ©orologiques de la NASA POWER.
**Pandas & PySpark** : manipulation et transformation de donnÃ©es massives.
**SQL/MySQL** : crÃ©ation de tables, insertion par batch, gestion des transactions.
**Airflow** : orchestration de pipeline ETL, gestion des dÃ©pendances, planification.
**Power BI** : analyse statistique et visualisation interactive des donnÃ©es.
**Bonnes pratiques ETL** : modularitÃ© du code, robustesse, logs dÃ©taillÃ©s.

---

## Conclusion

Ce projet met en Å“uvre un processus ETL complet de collecte, transformation, et stockage des donnÃ©es mÃ©tÃ©orologiques.
Il offre un pipeline efficace et automatisÃ© pour analyser des donnÃ©es complexes et en tirer des insights pertinents.

## Auteurs

- **Nom** : El Hadji Ablaye Galoup DIOP  
- **Email** : elhadjiablayegaloupdiop@gmail.com


