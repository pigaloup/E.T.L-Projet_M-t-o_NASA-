# üåç Projet E.T.L M√©t√©o NASA avec Airflow, Spark, MySQL et Analyse M√©t√©orologique

## üìå Description : 

Ce projet met en place un **pipeline ETL automatis√©** pour collecter, transformer et charger des donn√©es m√©t√©orologiques issues de l‚ÄôAPI **NASA POWER**.  
L‚Äôobjectif est de construire une base de donn√©es exploitable pour l‚Äôanalyse climatique de plusieurs pays d‚ÄôAfrique de l‚ÄôOuest (S√©n√©gal, Mali, C√¥te d‚ÄôIvoire, Guin√©e, Nigeria, Ghana, Burkina Faso). Le pipeline est orchestr√© par **Apache Airflow**, qui planifie et supervise l‚Äôensemble du processus. Les donn√©es brutes sont nettoy√©es et transform√©es gr√¢ce √† **Apache Spark**, puis les r√©sultats finalis√©s sont stock√©s dans une base de donn√©es **MySQL** pour faciliter leur exploitation et leur analyse.
Le projet comprend √©galement des √©tapes d'analyse statistique et de visualisation des donn√©es dans [**Power BI**](https://github.com/pigaloup/E.T.L-AIRFLOW_Projet_Meteo_NASA-/blob/main/Readme_POWERBI.md).

---

## ‚öôÔ∏è Architecture du projet

### √âtapes ETL
1. **Extraction** :
   - Requ√™te API NASA POWER (param√®tres m√©t√©o : temp√©rature, humidit√©, vent, pr√©cipitations, etc.).
   - Donn√©es collect√©es pour plusieurs villes par pays.
   - Utilisation de **multithreading** (`concurrent.futures`) pour acc√©l√©rer les appels API.
   - Sauvegarde initiale en **CSV**.

2. **Transformation et nettoyage des donn√©es** :
   - Chargement des donn√©es brutes dans **PySpark**.
   - Nettoyage : suppression des doublons, gestion des valeurs manquantes, filtrage des anomalies.
   - Conversion des dates en colonnes distinctes pour la date et l'heure.
   - Renommage des colonnes pour plus de lisibilit√© (`temperature_air`, `pression`, `humidite_relative`, etc.).
   - Export des donn√©es nettoy√©es en **CSV**.

3. **Chargement** :
   - Connexion √† une base **MySQL**.
   - Cr√©ation automatique de la base et de la table si elles n‚Äôexistent pas.
   - Insertion des donn√©es par **batchs** pour optimiser les performances.
   - Gestion des erreurs et rollback en cas d‚Äô√©chec.

4. [**Visualisation des donn√©es**](https://github.com/pigaloup/E.T.L-AIRFLOW_Projet_Meteo_NASA-/blob/main/Readme_POWERBI.md) :
Utilisation de **Power BI** pour cr√©er des visualisations interactives les donn√©es m√©t√©orologiques, en analysant les variables telles que :

---

## üìÇ Structure du DAG Airflow :

Le DAG `nasa_etl_pipeline` orchestre les 3 √©tapes :

- **Task 1 : `extract_data`** ‚Üí Appelle la fonction `get_data` et sauvegarde le CSV brut.  
- **Task 2 : `transform_data`** ‚Üí Nettoie et transforme les donn√©es avec Spark.  
- **Task 3 : `load_data`** ‚Üí Charge les donn√©es dans MySQL.


## üñºÔ∏è Sch√©ma d‚Äôarchitecture du pipeline ETL:

Voici une repr√©sentation visuelle du pipeline ETL orchestr√© avec Apache Airflow :

![Sch√©ma d‚Äôarchitecture du pipeline ETL](ETL+AIRFLOW/ETL_ARCHITECTURE.jpg)

Ce sch√©ma illustre le flux complet :

- Les donn√©es sont extraites depuis l‚ÄôAPI NASA POWER.

- Airflow orchestre le pipeline.

- Spark nettoie et transforme les donn√©es.

- Les r√©sultats sont sauvegard√©s en CSV puis ins√©r√©s dans MySQL.

- Power BI permet ensuite d‚Äôanalyser et de visualiser les donn√©es sous forme de rapports interactifs.

---

## üìä R√©sultats attendus apr√©s √©x√©cution:

- Base MySQL meteo_db_PAYS_AIRFLOW contenant la table meteo_data_PAYS_AIRFLOW.
- Donn√©es m√©t√©orologiques nettoy√©es et pr√™tes pour l‚Äôanalyse.
- Fichiers CSV interm√©diaires pour audit et tra√ßabilit√©.
- Logs d√©taill√©s (etl_execution.log) pour suivre l‚Äôex√©cution.
  
---

## üõ†Ô∏è Comp√©tences acquises:

En r√©alisant ce projet, j‚Äôai d√©velopp√© les comp√©tences suivantes :

- **Python avanc√©** :connexion avec la base de donn√©e Mysql, gestion des exceptions, logging, multithreading.
- **API REST** : Pour la collecte des donn√©es m√©t√©orologiques de la NASA POWER.
- **Pandas & PySpark** : manipulation et transformation de donn√©es massives.
- **SQL/MySQL** : cr√©ation de tables, insertion par batch, gestion des transactions.
- **Airflow** : orchestration de pipeline ETL, gestion des d√©pendances, planification.
- **Power BI** : analyse statistique et visualisation interactive des donn√©es.
- **Bonnes pratiques ETL** : modularit√© du code, robustesse, logs d√©taill√©s.

---

## Conclusion

Ce projet met en ≈ìuvre un processus ETL complet de collecte, transformation, et stockage des donn√©es m√©t√©orologiques.
Il offre un pipeline efficace et automatis√© pour analyser des donn√©es complexes et en tirer des insights pertinents.

## Auteurs

- **Nom** : El Hadji Ablaye Galoup DIOP  
- **Email** : elhadjiablayegaloupdiop@gmail.com


